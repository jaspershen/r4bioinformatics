[{"path":"index.html","id":"welcome","chapter":"1 Welcome","heading":"1 Welcome","text":"这本书用来系统记录在学习过程中的遇到的问题,学到的知识.can contact via social websites : Personal website GitHub Wechat QQ shenxt stanford.edu Linkedin","code":""},{"path":"r4bioinformatics.html","id":"r4bioinformatics","chapter":"2 R for Bioinformatics analysis","heading":"2 R for Bioinformatics analysis","text":"首先从Markdown的基础语法开始.","code":""},{"path":"r4bioinformatics.html","id":"markdown语法","chapter":"2 R for Bioinformatics analysis","heading":"2.1 Markdown语法","text":"markdown语法一般是使用符号转变为特殊格式.这样,看起来markdown文件都是plain text(纯文本),但是渲染之后,就可以得到特殊格式的文件了.很多语法没有必要记住,只需要记住大概常用的几个就好,遇到不会的,直接google就可以.","code":""},{"path":"cross.html","id":"cross","chapter":"3 Cross-references","heading":"3 Cross-references","text":"Cross-references make easier readers find link elements book.","code":""},{"path":"cross.html","id":"chapters-and-sub-chapters","chapter":"3 Cross-references","heading":"3.1 Chapters and sub-chapters","text":"two steps cross-reference heading:Label heading: # Hello world {#nice-label}.\nLeave label like automated heading generated based heading title: example, # Hello world = # Hello world {#hello-world}.\nlabel un-numbered heading, use: # Hello world {-#nice-label} {# Hello world .unnumbered}.\nLeave label like automated heading generated based heading title: example, # Hello world = # Hello world {#hello-world}.label un-numbered heading, use: # Hello world {-#nice-label} {# Hello world .unnumbered}.Next, reference labeled heading anywhere text using \\@ref(nice-label); example, please see Chapter 3.\nprefer text link instead numbered reference use: text want can go .\nprefer text link instead numbered reference use: text want can go .","code":""},{"path":"cross.html","id":"captioned-figures-and-tables","chapter":"3 Cross-references","heading":"3.2 Captioned figures and tables","text":"Figures tables captions can also cross-referenced elsewhere book using \\@ref(fig:chunk-label) \\@ref(tab:chunk-label), respectively.See Figure 3.1.\nFigure 3.1: nice figure!\nDon’t miss Table 3.1.Table 3.1: nice table!","code":"\npar(mar = c(4, 4, .1, .1))\nplot(pressure, type = 'b', pch = 19)\nknitr::kable(\n  head(pressure, 10), caption = 'Here is a nice table!',\n  booktabs = TRUE\n)"},{"path":"parts.html","id":"parts","chapter":"4 Parts","heading":"4 Parts","text":"can add parts organize one book chapters together. Parts can inserted top .Rmd file, first-level chapter heading file.Add numbered part: # (PART) Act one {-} (followed # chapter)Add unnumbered part: # (PART\\*) Act one {-} (followed # chapter)Add appendix special kind un-numbered part: # (APPENDIX) stuff {-} (followed # chapter). Chapters appendix prepended letters instead numbers.","code":""},{"path":"footnotes-and-citations.html","id":"footnotes-and-citations","chapter":"5 Footnotes and citations","heading":"5 Footnotes and citations","text":"","code":""},{"path":"footnotes-and-citations.html","id":"footnotes","chapter":"5 Footnotes and citations","heading":"5.1 Footnotes","text":"Footnotes put inside square brackets caret ^[]. Like one 1.","code":""},{"path":"footnotes-and-citations.html","id":"citations","chapter":"5 Footnotes and citations","heading":"5.2 Citations","text":"Reference items bibliography file(s) using @key.example, using bookdown package2 (check last code chunk index.Rmd see citation key added) sample book, built top R Markdown knitr3 (citation added manually external file book.bib).\nNote .bib files need listed index.Rmd YAML bibliography key.bs4_book theme makes footnotes appear inline click . example book, added csl: chicago-fullnote-bibliography.csl index.Rmd YAML, include .csl file. download new style, recommend: https://www.zotero.org/styles/RStudio Visual Markdown Editor can also make easier insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations","code":""},{"path":"blocks.html","id":"blocks","chapter":"6 Blocks","heading":"6 Blocks","text":"","code":""},{"path":"blocks.html","id":"equations","chapter":"6 Blocks","heading":"6.1 Equations","text":"equation.\\[\\begin{equation}\n  f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k}\n  \\tag{6.1}\n\\end{equation}\\]may refer using \\@ref(eq:binom), like see Equation (6.1).","code":""},{"path":"blocks.html","id":"theorems-and-proofs","chapter":"6 Blocks","heading":"6.2 Theorems and proofs","text":"Labeled theorems can referenced text using \\@ref(thm:tri), example, check smart theorem 6.1.Theorem 6.1  right triangle, \\(c\\) denotes length hypotenuse\n\\(\\) \\(b\\) denote lengths two sides, \n\\[^2 + b^2 = c^2\\]Read https://bookdown.org/yihui/bookdown/markdown-extensions--bookdown.html.","code":""},{"path":"blocks.html","id":"callout-blocks","chapter":"6 Blocks","heading":"6.3 Callout blocks","text":"bs4_book theme also includes special callout blocks, like .rmdnote.can use markdown inside block.user define appearance blocks LaTeX output.may also use: .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning block name.R Markdown Cookbook provides help use custom blocks design callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html","code":"\nhead(beaver1, n = 5)\n#>   day time  temp activ\n#> 1 346  840 36.33     0\n#> 2 346  850 36.34     0\n#> 3 346  900 36.35     0\n#> 4 346  910 36.42     0\n#> 5 346  920 36.55     0"},{"path":"sharing-your-book.html","id":"sharing-your-book","chapter":"7 Sharing your book","heading":"7 Sharing your book","text":"","code":""},{"path":"sharing-your-book.html","id":"publishing","chapter":"7 Sharing your book","heading":"7.1 Publishing","text":"HTML books can published online, see: https://bookdown.org/yihui/bookdown/publishing.html","code":""},{"path":"sharing-your-book.html","id":"pages","chapter":"7 Sharing your book","heading":"7.2 404 pages","text":"default, users directed 404 page try access webpage found. ’d like customize 404 page instead using default, may add either _404.Rmd _404.md file project root use code /Markdown syntax.","code":""},{"path":"sharing-your-book.html","id":"metadata-for-sharing","chapter":"7 Sharing your book","heading":"7.3 Metadata for sharing","text":"Bookdown HTML books provide HTML metadata social sharing platforms like Twitter, Facebook, LinkedIn, using information provide index.Rmd YAML. setup, set url book path cover-image file. book’s title description also used.bs4_book provides enhanced metadata social sharing, chapter shared unique description, auto-generated based content.Specify book’s source repository GitHub repo _output.yml file, allows users view chapter’s source file suggest edit. Read features output format :https://pkgs.rstudio.com/bookdown/reference/bs4_book.htmlOr use:","code":"\n?bookdown::bs4_book"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""},{"path":"network.html","id":"network","chapter":"8 Network分析总结","heading":"8 Network分析总结","text":"significant applications demonstrated chapter.","code":""},{"path":"network.html","id":"example-one","chapter":"8 Network分析总结","heading":"8.1 Example one","text":"","code":""},{"path":"network.html","id":"example-two","chapter":"8 Network分析总结","heading":"8.2 Example two","text":"","code":""},{"path":"tidyverse_stringr.html","id":"tidyverse_stringr","chapter":"9 Tidyverse用于数据分析stringr","heading":"9 Tidyverse用于数据分析stringr","text":"stringr是R中进行文本处理的包.cheatsheet可以看这里.https://github.com/rstudio/cheatsheets/blob/master/strings.pdf","code":""},{"path":"tidyverse_stringr.html","id":"安装","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.1 安装","text":"","code":"\n# Install the released version from CRAN:\ninstall.packages(\"stringr\")\n\n# Install the cutting edge development version from GitHub:\n# install.packages(\"devtools\")\ndevtools::install_github(\"tidyverse/stringr\")"},{"path":"tidyverse_stringr.html","id":"rstudio-addin","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.2 Rstudio Addin","text":"使用Rstudio Addin,可以很方便的使用正则表达式.需要安装一个包:安装结束之后,可以在Addins中找到.","code":"\nif(!require(remotes)){\n  install.packages(\"remotes\")\n}\nif(!require(regexplain)){\nremotes::install_github(\"gadenbuie/regexplain\")\n}"},{"path":"tidyverse_stringr.html","id":"pattern-matching","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3 Pattern matching","text":"","code":""},{"path":"tidyverse_stringr.html","id":"计算一个文本中符合要求的数目","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.1 计算一个文本中符合要求的数目","text":"使用str_count()函数:比如要统计某个单词中某个字母的个数:其中第二个参数pattern是支持正则表达式的.","code":"\nlibrary(stringr)\nlibrary(regexplain)\nfruit <- c(\"apple\", \"banana\", \"pear\", \"pineapple\")\nstr_count(fruit, \"a\")\n#> [1] 1 3 1 1\n\nstr_count(fruit, c(\"a\", \"b\", \"p\", \"p\"))\n#> [1] 1 1 1 3"},{"path":"tidyverse_stringr.html","id":"判断一个文本中是否存在一个pattern","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.2 判断一个文本中是否存在一个pattern","text":"使用str_detect()函数.其中negate是在stringr中的很多函数都有的一个参数,如果设置为TRUE,就会返回没有match到的内容.","code":"\nstr_detect(string, pattern, negate = FALSE)\nfruit <- c(\"apple\", \"banana\", \"pear\", \"pinapple\")\nstr_detect(fruit, \"a\")\n#> [1] TRUE TRUE TRUE TRUE"},{"path":"tidyverse_stringr.html","id":"从文本中提取pattern","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.3 从文本中提取pattern","text":"有两个函数,str_extract和str_extract_all.用法如下:从文本中提取符合要求的文本.例子:\\\\d是一种正则表达式的写法,代表任意数字.上面的代码代表我们想要从每个文本中提取所有的数字.如果没有数字,那么就会返回NA.[-z]+代表任意一个小写字母,然后重复1次或者多次.\\\\b代表字符的边界.\\\\b[-z]{1,4}\\\\b代表一个字符的边界+重复1-4次的任意小写字母+一个字符的边界.可以看到,只会提取出第一个字母.如果想要把一个字符的所有符合要求的pattern都提取出来,可以使用str_extract_all.可以看到,这时候得到的就是一个和string同样长度的list.会把每个string中的符合要求的pattern都提取出来.我们注意到str_extract_all()有一个参数:simplify,它能够将返回的结果变为一个matrix:","code":"\nstr_extract(string, pattern)\nstr_extract_all(string, pattern, simplify = FALSE)\nshopping_list <- c(\"apples x4\", \"bag of flour\", \"bag of sugar\", \"milk x2\")\nstr_extract(shopping_list, \"\\\\d\")\n#> [1] \"4\" NA  NA  \"2\"\nshopping_list <- c(\"apples x4\", \"bag of flour\", \"bag of sugar\", \"milk x2\")\nstr_extract(shopping_list, \"[a-z]+\")\n#> [1] \"apples\" \"bag\"    \"bag\"    \"milk\"\nshopping_list <- c(\"apples x4\", \"bag of flour\", \"bag of sugar\", \"milk x2\")\nstr_extract(shopping_list, \"\\\\b[a-z]{1,4}\\\\b\")\n#> [1] NA     \"bag\"  \"bag\"  \"milk\"\nshopping_list <- c(\"apples x4\", \"bag of flour\", \"bag of sugar\", \"milk x2\")\nstr_extract_all(shopping_list, \"[a-z]+\")\n#> [[1]]\n#> [1] \"apples\" \"x\"     \n#> \n#> [[2]]\n#> [1] \"bag\"   \"of\"    \"flour\"\n#> \n#> [[3]]\n#> [1] \"bag\"   \"of\"    \"sugar\"\n#> \n#> [[4]]\n#> [1] \"milk\" \"x\"\nstr_extract_all(shopping_list, \"\\\\b[a-z]+\\\\b\")\n#> [[1]]\n#> [1] \"apples\"\n#> \n#> [[2]]\n#> [1] \"bag\"   \"of\"    \"flour\"\n#> \n#> [[3]]\n#> [1] \"bag\"   \"of\"    \"sugar\"\n#> \n#> [[4]]\n#> [1] \"milk\"\nstr_extract_all(shopping_list, \"\\\\d\")\n#> [[1]]\n#> [1] \"4\"\n#> \n#> [[2]]\n#> character(0)\n#> \n#> [[3]]\n#> character(0)\n#> \n#> [[4]]\n#> [1] \"2\"\nshopping_list <- c(\"apples x4\", \"bag of flour\", \"bag of sugar\", \"milk x2\")\nstr_extract_all(shopping_list, \"[a-z]+\", simplify = TRUE)\n#>      [,1]     [,2] [,3]   \n#> [1,] \"apples\" \"x\"  \"\"     \n#> [2,] \"bag\"    \"of\" \"flour\"\n#> [3,] \"bag\"    \"of\" \"sugar\"\n#> [4,] \"milk\"   \"x\"  \"\"\nstr_extract_all(shopping_list, \"\\\\b[a-z]+\\\\b\", simplify = TRUE)\n#>      [,1]     [,2] [,3]   \n#> [1,] \"apples\" \"\"   \"\"     \n#> [2,] \"bag\"    \"of\" \"flour\"\n#> [3,] \"bag\"    \"of\" \"sugar\"\n#> [4,] \"milk\"   \"\"   \"\"\nstr_extract_all(shopping_list, \"\\\\d\", simplify = TRUE)\n#>      [,1]\n#> [1,] \"4\" \n#> [2,] \"\"  \n#> [3,] \"\"  \n#> [4,] \"2\""},{"path":"tidyverse_stringr.html","id":"确定某个pattern在文本中的位置","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.4 确定某个pattern在文本中的位置","text":"两个函数:例子:$代表以某个东西结尾.然后我们再查找字母a在所有字符中的位置.如果没有符合要求的pattern,则会返回NA.也可以设置pattern为一个长度和string相同的vector.如果想要查找所有符合要求的pattern的位置,要使用str_locate_all()函数:返回是一个list.","code":"\nstr_locate(string, pattern)\nstr_locate_all(string, pattern)\nfruit <- c(\"apple\", \"banana\", \"pear\", \"pineapple\")\nstr_locate(fruit, \"$\")\nstr_locate(fruit, \"a\")\nstr_locate(fruit, \"e\")\nstr_locate(fruit, c(\"a\", \"b\", \"p\", \"p\"))\nstr_locate(fruit, \"a\")\nstr_locate_all(fruit, \"a\")"},{"path":"tidyverse_stringr.html","id":"从文本中提取extract匹配到的group","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.5 从文本中提取(extract)匹配到的group","text":"函数为:这两个函数跟str_extract()有些类似.例子:phone代表符合电话号码的格式:第一个group: 小括号括起来的,数字2-9其中一个,重复一次(后面没有限定数量,则代表重复一次);数字0-9.重复两次. 然后中间是-或者空格,或者任意一个字符.第一个group: 小括号括起来的,数字2-9其中一个,重复一次(后面没有限定数量,则代表重复一次);数字0-9.重复两次. 然后中间是-或者空格,或者任意一个字符.group 2: 小括号括起来的.0-9任意数字重复三次.然后中间是-或者空格,或者任意一个字符.group 2: 小括号括起来的.0-9任意数字重复三次.然后中间是-或者空格,或者任意一个字符.group 3: 小括号括起来的.0-9任意数字重复四次.group 3: 小括号括起来的.0-9任意数字重复四次.这时候我们试试使用str_match()函数:可以看到,除了将整体pattern匹配出来之后,还将每个group(也就是括号括起来的部分)分别匹配出来了.另外一个例子:<(.*?)>其中的*?是贪婪用法,表示重复任意次,但尽可能少重复.请参考这一章正则表达式.","code":"\nstr_match(string, pattern)\nstr_match_all(string, pattern)\nstrings <- c(\" 219 733 8965\", \"329-293-8753 \", \"banana\", \"595 794 7569\",\n  \"387 287 6718\", \"apple\", \"233.398.9187  \", \"482 952 3315\",\n  \"239 923 8115 and 842 566 4692\", \"Work: 579-499-7527\", \"$1000\",\n  \"Home: 543.355.3679\")\nphone <- \"([2-9][0-9]{2})[- .]([0-9]{3})[- .]([0-9]{4})\"\nstr_extract(strings, phone)\n#>  [1] \"219 733 8965\" \"329-293-8753\" NA            \n#>  [4] \"595 794 7569\" \"387 287 6718\" NA            \n#>  [7] \"233.398.9187\" \"482 952 3315\" \"239 923 8115\"\n#> [10] \"579-499-7527\" NA             \"543.355.3679\"\nstr_match(strings, phone)\n#>       [,1]           [,2]  [,3]  [,4]  \n#>  [1,] \"219 733 8965\" \"219\" \"733\" \"8965\"\n#>  [2,] \"329-293-8753\" \"329\" \"293\" \"8753\"\n#>  [3,] NA             NA    NA    NA    \n#>  [4,] \"595 794 7569\" \"595\" \"794\" \"7569\"\n#>  [5,] \"387 287 6718\" \"387\" \"287\" \"6718\"\n#>  [6,] NA             NA    NA    NA    \n#>  [7,] \"233.398.9187\" \"233\" \"398\" \"9187\"\n#>  [8,] \"482 952 3315\" \"482\" \"952\" \"3315\"\n#>  [9,] \"239 923 8115\" \"239\" \"923\" \"8115\"\n#> [10,] \"579-499-7527\" \"579\" \"499\" \"7527\"\n#> [11,] NA             NA    NA    NA    \n#> [12,] \"543.355.3679\" \"543\" \"355\" \"3679\"\nstr_extract_all(strings, phone)\n#> [[1]]\n#> [1] \"219 733 8965\"\n#> \n#> [[2]]\n#> [1] \"329-293-8753\"\n#> \n#> [[3]]\n#> character(0)\n#> \n#> [[4]]\n#> [1] \"595 794 7569\"\n#> \n#> [[5]]\n#> [1] \"387 287 6718\"\n#> \n#> [[6]]\n#> character(0)\n#> \n#> [[7]]\n#> [1] \"233.398.9187\"\n#> \n#> [[8]]\n#> [1] \"482 952 3315\"\n#> \n#> [[9]]\n#> [1] \"239 923 8115\" \"842 566 4692\"\n#> \n#> [[10]]\n#> [1] \"579-499-7527\"\n#> \n#> [[11]]\n#> character(0)\n#> \n#> [[12]]\n#> [1] \"543.355.3679\"\nstr_match_all(strings, phone)\n#> [[1]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"219 733 8965\" \"219\" \"733\" \"8965\"\n#> \n#> [[2]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"329-293-8753\" \"329\" \"293\" \"8753\"\n#> \n#> [[3]]\n#>      [,1] [,2] [,3] [,4]\n#> \n#> [[4]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"595 794 7569\" \"595\" \"794\" \"7569\"\n#> \n#> [[5]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"387 287 6718\" \"387\" \"287\" \"6718\"\n#> \n#> [[6]]\n#>      [,1] [,2] [,3] [,4]\n#> \n#> [[7]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"233.398.9187\" \"233\" \"398\" \"9187\"\n#> \n#> [[8]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"482 952 3315\" \"482\" \"952\" \"3315\"\n#> \n#> [[9]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"239 923 8115\" \"239\" \"923\" \"8115\"\n#> [2,] \"842 566 4692\" \"842\" \"566\" \"4692\"\n#> \n#> [[10]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"579-499-7527\" \"579\" \"499\" \"7527\"\n#> \n#> [[11]]\n#>      [,1] [,2] [,3] [,4]\n#> \n#> [[12]]\n#>      [,1]           [,2]  [,3]  [,4]  \n#> [1,] \"543.355.3679\" \"543\" \"355\" \"3679\"\nx <- c(\"<a> <b>\", \"<a> <>\", \"<a>\", \"\", NA)\nstr_match(x, \"<(.*?)> <(.*?)>\")\n#>      [,1]      [,2] [,3]\n#> [1,] \"<a> <b>\" \"a\"  \"b\" \n#> [2,] \"<a> <>\"  \"a\"  \"\"  \n#> [3,] NA        NA   NA  \n#> [4,] NA        NA   NA  \n#> [5,] NA        NA   NA\nstr_match_all(x, \"<(.*?)>\")\n#> [[1]]\n#>      [,1]  [,2]\n#> [1,] \"<a>\" \"a\" \n#> [2,] \"<b>\" \"b\" \n#> \n#> [[2]]\n#>      [,1]  [,2]\n#> [1,] \"<a>\" \"a\" \n#> [2,] \"<>\"  \"\"  \n#> \n#> [[3]]\n#>      [,1]  [,2]\n#> [1,] \"<a>\" \"a\" \n#> \n#> [[4]]\n#>      [,1] [,2]\n#> \n#> [[5]]\n#>      [,1] [,2]\n#> [1,] NA   NA\nstr_extract(x, \"<.*?>\")\n#> [1] \"<a>\" \"<a>\" \"<a>\" NA    NA\nstr_extract_all(x, \"<.*?>\")\n#> [[1]]\n#> [1] \"<a>\" \"<b>\"\n#> \n#> [[2]]\n#> [1] \"<a>\" \"<>\" \n#> \n#> [[3]]\n#> [1] \"<a>\"\n#> \n#> [[4]]\n#> character(0)\n#> \n#> [[5]]\n#> [1] NA"},{"path":"tidyverse_stringr.html","id":"从文本中去除匹配到的pattern","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.6 从文本中去除匹配到的pattern","text":"函数:与str_replace用法作用一致.但是str_replace可以替换成其他pattern.例子:","code":"\nstr_remove(string, pattern)\nstr_remove_all(string, pattern)\nfruits <- c(\"one apple\", \"two pears\", \"three bananas\")\nstr_remove(fruits, \"[aeiou]\")\n#> [1] \"ne apple\"     \"tw pears\"     \"thre bananas\"\nstr_remove_all(fruits, \"[aeiou]\")\n#> [1] \"n ppl\"    \"tw prs\"   \"thr bnns\""},{"path":"tidyverse_stringr.html","id":"从文本中替换匹配到的pattern","chapter":"9 Tidyverse用于数据分析stringr","heading":"9.3.7 从文本中替换匹配到的pattern","text":"函数:例子:从这个例子可以看出来,replacement也可以是一个函数,将匹配到的所有pattern使用该函数转换之后替换.","code":"\nstr_replace(string, pattern, replacement)\nstr_replace_all(string, pattern, replacement)\nfruits <- c(\"one apple\", \"two pears\", \"three bananas\")\nstr_replace(fruits, \"[aeiou]\", \"-\")\n#> [1] \"-ne apple\"     \"tw- pears\"     \"thr-e bananas\"\nstr_replace_all(fruits, \"[aeiou]\", \"-\")\n#> [1] \"-n- -ppl-\"     \"tw- p--rs\"     \"thr-- b-n-n-s\"\nstr_replace_all(fruits, \"[aeiou]\", toupper)\n#> [1] \"OnE ApplE\"     \"twO pEArs\"     \"thrEE bAnAnAs\"\nstr_replace_all(fruits, \"b\", NA_character_)\n#> [1] \"one apple\" \"two pears\" NA\nstr_replace(fruits, \"([aeiou])\", \"\\\\1\\\\1\")\n#> [1] \"oone apple\"     \"twoo pears\"     \"threee bananas\""},{"path":"multiomics.html","id":"multiomics","chapter":"10 多组学分析","heading":"10 多组学分析","text":"","code":""},{"path":"multiomics.html","id":"wgcna","chapter":"10 多组学分析","heading":"10.1 WGCNA","text":"使用官方例子进行学习.https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/","code":""},{"path":"multiomics.html","id":"基础概念","chapter":"10 多组学分析","heading":"10.2 基础概念","text":"参考这篇文章.https://www.omicshare.com/class/Public/Upload/video/20170607150629336688.pdf","code":""},{"path":"multiomics.html","id":"无尺度网络scale-free-network","chapter":"10 多组学分析","heading":"10.2.1 无尺度网络(scale free network)","text":"基因符合无尺度分布无尺度网络是指大部分节点的degree(与其相连的node)非常少,而小部分的node与非常多的节点相连.如果使用数学语言进行描述:假设某个基因(node)的degree为m,统计网络中所有的基因的m值,然后以m值大小对基因进行分类,n为基因连接数为m的基因,那么m和n成反比.","code":""},{"path":"multiomics.html","id":"模块module和模块特征值","chapter":"10 多组学分析","heading":"10.2.2 模块(module)和模块特征值","text":"模块是指表达模式相似的一组基因.模块特征值:将一组基因归为一个模块之后,如果我们想对该模块进行定量化表示,就需要使用一个值来进行表示该模块在所有样品中的表达值.这时候一般是使用该模块中的所有基因进行PCA分析,然后使用PC1(主成分1)来表示.","code":""},{"path":"multiomics.html","id":"连通性-connectivity","chapter":"10 多组学分析","heading":"10.2.3 连通性 (Connectivity)","text":"一个基因和其他所有基因的连接程度,一般只在模块内计算,称之为连接度(connectivity)或者degree.对于非权重网络来说,因为edge没有权重,因此有边就是1,没有边就是0,因此degree就是该基因的边的个数.对于权重网络,边是有权重的,因此,每个基因的degree是值所有边的权重之和.","code":""},{"path":"multiomics.html","id":"hub-gene","chapter":"10 多组学分析","heading":"10.2.4 Hub gene","text":"在一个模块中,degree排名靠前的基因,说明其处于枢纽位置,称之为hug gene.","code":""},{"path":"multiomics.html","id":"wgcna-介绍","chapter":"10 多组学分析","heading":"10.3 WGCNA 介绍","text":"全称为weighted gene co-expression network analysis.将研究重点从单个基因转移到模块.计算的两个关键步骤:1)计算基因间的相关性,2)将基因画为模块.","code":""},{"path":"multiomics.html","id":"计算基因的相关性","chapter":"10 多组学分析","heading":"10.3.1 计算基因的相关性","text":"计算基因的两两间相关性\\[S_{ij} = |cor(x_i,x_j)|\\]其中\\(S_{ij}\\)是基因相关性矩阵.无尺度化也就是对原始的相关性矩阵进行变换.构建相邻矩阵.为了知道两个基因表达是否类似,需要设定一个阈值(threshold),只有当基因之间的相关性大于该阈值,才认为他们之间是相似的,比如0.8.否则不相似,因此,相邻矩阵就是描述两个基因之间是否相似的矩阵.如果使用硬阈值,得到的相邻矩阵应该就是0,1矩阵.但是这种办法的缺点就在于怎么确定阈值?在WGCNA中,使用的是软阈值的办法,软阈值的思路是通过加权函数,将相邻矩阵中的元素连续化:\\[a_{ij} = power(S_{ij}, \\beta) = |S_{ij}|^\\beta\\]在这里使用的是power函数.需要设置soft threshold,这时候需要确定power函数的参数β.如何选择合适的β呢?WGCNA的作者提供了两个标准:网络更接近无尺度网络; 2) 尽可能保留连通性信息.β是WGCNA中第一个关键参数,后面在实际例子中进行详解.基因间表达相关性上面我们得到了基因间的相邻矩阵,WGCNA为了更准确的表示两个基因间表达的相似性,还引入了另外一个概念,也就是TOM(Topological Overlap Matrix),拓扑重叠矩阵,她代表的是两个基因间相似性等于直接相关+间接相关.计算公式如下:\\[TOM_{ij} = \\frac{\\displaystyle \\sum_{u}{a_{iu}a_{uj}+a_{ij}}}{min(k_i,k_j)+1-a_{ij}}\\]其中\\(\\displaystyle \\sum_{u}{a_{iu}a_{uj}}\\)代表基因i和j.\\(a_{ij}\\)代表基因i和基因j的在相邻矩阵中的值.因此,上式中的分子代表的是基因i和j直接联系加上一阶(基因u)基因联系的和.而\\(k_i\\)代表基因k的degree,也就是基因k和其他所有直接连接的基因的关系之和.TOM值的取值范围也是0-1.TOM值也就是WGCNA中最后的weight值.聚类得到TOM值之后,也就得到了TOM矩阵.然后利用TOM矩阵,就可以对基因进行聚类了.WGCNA中使用的是层级聚类,聚类结束之后,就可以对分支进行剪切区分.得到module.后续生物学意义挖掘得到模块之后,可以对模块进行生物学意义的挖掘.","code":""},{"path":"multiomics.html","id":"使用wgcna包进行分析","chapter":"10 多组学分析","heading":"10.4 使用WGCNA包进行分析","text":"","code":""},{"path":"multiomics.html","id":"data-input-and-cleaning","chapter":"10 多组学分析","heading":"10.4.1 Data input and cleaning","text":"首先读取数据并清洗可以看到该数据行是基因,列是样品.一共3600个基因.然后将基因的描述列去掉.并且将其转置,得到的matrix行是样品,列是基因.然后需要去除掉数据(表达矩阵)中的outlier基因和样品.使用的是goodSamplesGenes()函数.该函数用来检查数据中的基因是否符合要求,返回结果是一个list.如果allOK为TRUE,则代表通过检查,如果不是TRUE,则需要手动去除基因和样品:我们可以使用数据对样品进行聚类,然后观察有哪些明显的outlier samples.我们可以设定剪枝的阈值,比如我们设置为15,然后使用cutreeStatic()函数对样品进行分类.可以明显的看到一个outlier sample(0).可以手动删除,也可以自动的办法.datExpr就是我们最终用来进行network分析的表达数据.一共3600个基因,134个样品.下面我们需要读取clinical data.后续需要使用clinical data和模块数据做分析.这时候我们得到的datTraits就是clinicaldata,其中行为样品,列为变量.下面我们来看看样品的临床数据的热图和样品的基因的聚类.最后,把数据保存下来,准备后续的分析.","code":"\nlibrary(WGCNA)\nlibrary(tidyverse)\nfemData <- \n  read.csv(\"WGCNA_test/LiverFemale3600.csv\")\ndim(femData)\ncolnames(femData) %>% head()\ndata_exp0 <-\n  as.data.frame(t(femData[, -c(1:8)]), stringsAsFactors = FALSE)\ncolnames(data_exp0) = femData$substanceBXH\nrownames(data_exp0) = colnames(femData)[-c(1:8)]\ngsg <- goodSamplesGenes(data_exp0, verbose = 3)\ngsg$allOK\nif (!gsg$allOK){\n  # Remove the offending genes and samples from the data:\n  data_exp0 <- data_exp0[gsg$goodSamples, gsg$goodGenes]\n}\nsampleTree <- hclust(dist(data_exp0), method = \"average\")\nplot(\n  sampleTree,\n  main = \"Sample clustering to detect outliers\",\n  sub = \"\",\n  xlab = \"\",\n  cex.lab = 1,\n  cex.axis = 1,\n  cex.main = 1\n)\n# Determine cluster under the line\nclust = cutreeStatic(sampleTree, cutHeight = 15, minSize = 10)\ntable(clust)\n# clust 1 contains the samples we want to keep.\nkeepSamples = which(clust == 1)\ndatExpr = data_exp0[keepSamples,]\nnGenes = ncol(datExpr)\nnSamples = nrow(datExpr)\nnGenes\nnSamples\ntraitData <- read.csv(\"WGCNA_test/ClinicalTraits.csv\")\ndim(traitData)\nnames(traitData)\n# remove columns that hold information we do not need.\nallTraits = traitData[, -c(31, 16)]\nallTraits = allTraits[, c(2, 11:36)]\ndim(allTraits)\nnames(allTraits)\n# Form a data frame analogous to expression data that will hold the clinical traits.\nfemaleSamples = rownames(datExpr)\ntraitRows = match(femaleSamples, allTraits$Mice)\ndatTraits = allTraits[traitRows, -1]\nrownames(datTraits) = allTraits[traitRows, 1]\ncollectGarbage()\nsum(rownames(datTraits) == rownames(datExpr))\n# Re-cluster samples\nsampleTree2 <- hclust(dist(datExpr), method = \"average\")\n# Convert traits to a color representation: white means low, red means high, grey means missing entry\ntraitColors = numbers2colors(datTraits, signed = FALSE)\n# Plot the sample dendrogram and the colors underneath.\nplotDendroAndColors(dendro = sampleTree2,\n                    colors = traitColors,\n                    groupLabels = names(datTraits),\n                    main = \"Sample dendrogram and trait heatmap\")\nsave(datExpr, datTraits, file = \"WGCNA_test/FemaleLiver-01-dataInput.RData\")"},{"path":"multiomics.html","id":"network-analysis-of-liver-expression-data-in-female-mice","chapter":"10 多组学分析","heading":"10.4.2 Network analysis of liver expression data in female mice","text":"数据都准备好之后,下面就是做网络分析和module detection.首先需要设置R运行环境,主要是要能够进行多线程处理,然后读取数据:Automatic network construction module detectionWGCNA的第一个重要参数,就是构建相邻矩阵是的power函数的参数β.首先需要选择合适的soft-thresholding power在WGCNA中,使用pickSoftThreshold()函数.一般需要选择一系列candidate powers,然后根据结果进行选择.注意,这段代码在Rstudio中不能运行,运行出错,需要到R自带IDE或者终端中运行.左边图显示的是power和scale free topology fit的关系,右图显示的是power和mean connectivity的关系,一般选择能够使scale free topology fit达到最大时的最小的power.这里我们选择6.确定了power(β)参数之后,后面使用blockwiseModules()函数就可以得到modules.dataExpr是基因表达数据,行是样品,列基因.在这里我们选择了soft thresholding power 6, 然后最小module size设置为30.mergeCutHeight用来控制merge module.maxBlockSize: 是指最大的module的基因数量,默认为5000.net是最终的分类结果.下面看一下分类结果.使用颜色来表示module,代表这里面有18个module.标记为0的基因代表没有归为任何一类module.下面我们把module画出来.然后将结果保存,用于后续的分析.","code":"\nenableWGCNAThreads(nThreads = 6)\n# Load the data saved in the first part\nlnames = load(file = \"WGCNA_test/FemaleLiver-01-dataInput.RData\")\n#The variable lnames contains the names of loaded variables.\nlnames\n# Choose a set of soft-thresholding powers\npowers = c(c(1:10), seq(from = 12, to = 20, by = 2))\n# Call the network topology analysis function\nsft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)\nsave(sft, file = \"WGCNA_test/sft\")\nload(\"WGCNA_test/sft\")\npowers = c(c(1:10), seq(from = 12, to = 20, by = 2))\n# Scale-free topology fit index as a function of the soft-thresholding power\nsft$fitIndices %>% \n  ggplot(aes(x = Power, y = -sign(slope) * SFT.R.sq)) +\n  geom_hline(yintercept = 0.9, col = \"red\") +\n  geom_point(size = 2, shape = 16) +\n  ggrepel::geom_text_repel(aes(x = Power, y = -sign(slope) * SFT.R.sq, label = Power),\n                           color = \"red\") +\n  labs(x = \"Soft Threshold (power)\", \n       y = \"Scale Free Topology Model Fit,signed R^2\") +\n  theme_bw() +\n  theme(axis.title = element_text(size = 15), \n        axis.text = element_text(size = 13))\n# Mean connectivity as a function of the soft-thresholding power\nsft$fitIndices %>% \n  ggplot(aes(x = Power, y = mean.k.)) +\n  geom_point(size = 2, shape = 16) +\n  ggrepel::geom_text_repel(aes(x = Power, y = mean.k., label = Power),\n                           color = \"red\") +\n  labs(x = \"Soft Threshold (power)\", \n       y = \"Mean Connectivity\") +\n  theme_bw() +\n  theme(axis.title = element_text(size = 15), \n        axis.text = element_text(size = 13))\nnet <- blockwiseModules(\n  datExpr,\n  power = 6,\n  TOMType = \"unsigned\",\n  minModuleSize = 30,\n  reassignThreshold = 0,\n  mergeCutHeight = 0.25,\n  numericLabels = TRUE,\n  pamRespectsDendro = FALSE,\n  saveTOMs = TRUE,\n  saveTOMFileBase = \"femaleMouseTOM\",\n  verbose = 3\n)\nnames(net)\ntable(net$colors)\n# Convert labels to colors for plotting\nmergedColors = labels2colors(net$colors)\n# Plot the dendrogram and the module colors underneath\nplotDendroAndColors(\n  net$dendrograms[[1]],\n  mergedColors[net$blockGenes[[1]]],\n  \"Module colors\",\n  dendroLabels = FALSE,\n  hang = 0.03,\n  addGuide = TRUE,\n  guideHang = 0.05\n)\nmoduleLabels = net$colors\nmoduleColors = labels2colors(net$colors)\nMEs = net$MEs\n\ngeneTree = net$dendrograms[[1]]\n\nsave(MEs, moduleLabels, moduleColors, geneTree, net,\n     file = \"WGCNA_test/FemaleLiver-02-networkConstruction-auto.RData\")"},{"path":"multiomics.html","id":"relating-modules-to-external-information-and-identifying-important","chapter":"10 多组学分析","heading":"10.4.3 Relating modules to external information and identifying important","text":"首先加载上一步产生的数据:然后我们想要找到和clinical data关系非常紧密的module.对于每个module的来说,都有一个eigengene,也就是其PCA分析的第一主成分,用来代表该module在每个样品中的含量.这个矩阵除了可以从最终的结果net中直接得到,还可以使用下面的函数moduleEigengenes得到.我们也可以把这个数据和从net中直接得到的对比看一下.然后我们使用WGCNA中的cor函数计算module和clinical data的相关性.下面对correlation进行可视化:从上图中可以看出weight_g跟一些module相关性非常强.Gene relationship trait important modules: Gene Significance Module MembershipIntramodular analysis: identifying genes high GS MMSummary output network analysis results","code":"\nlnames = load(file = \"WGCNA_test/FemaleLiver-01-dataInput.RData\");\n#The variable lnames contains the names of loaded variables.\nlnames\n# Load network data saved in the second part.\nlnames = load(file = \"WGCNA_test/FemaleLiver-02-networkConstruction-auto.RData\");\nlnames\n# Recalculate MEs with color labels\nMEs0 = moduleEigengenes(expr = datExpr, colors = moduleColors)$eigengenes\nMEs = orderMEs(MEs0)\ntest <- net$MEs\ndata.frame(colnames(test), colnames(MEs), stringsAsFactors = FALSE) %>% \n  dplyr::distinct() %>% \n  dplyr::arrange()\n\ndata.frame(moduleColors, net$colors, stringsAsFactors = FALSE) %>% \n  dplyr::distinct() %>% \n  dplyr::arrange()\n# Define numbers of genes and samples\nnGenes = ncol(datExpr)\nnSamples = nrow(datExpr)\nmoduleTraitCor = WGCNA::cor(MEs, datTraits, use = \"p\")\nmoduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples)\n# Will display correlations and their p-values\ntextMatrix = paste(signif(moduleTraitCor, 2), \"\\n(\",\nsignif(moduleTraitPvalue, 1), \")\", sep = \"\")\ndim(textMatrix) = dim(moduleTraitCor)\npar(mar = c(6, 8.5, 3, 3))\n# Display the correlation values within a heatmap plot\nlabeledHeatmap(Matrix = moduleTraitCor,\nxLabels = names(datTraits),\nyLabels = names(MEs),\nySymbols = names(MEs),\ncolorLabels = FALSE,\ncolors = greenWhiteRed(50),\n# textMatrix = textMatrix,\nsetStdMargins = FALSE,\ncex.text = 0.5,\nzlim = c(-1,1),\nmain = paste(\"Module-trait relationships\"))\n# Define variable weight containing the weight column of datTrait\nweight = as.data.frame(datTraits$weight_g)\ncolnames(weight) = \"weight\"\n# names (colors) of the modules\nmodNames = substring(names(MEs), 3)\n##计算每个基因和module的相关性\ngeneModuleMembership = as.data.frame(WGCNA::cor(datExpr, MEs, use = \"p\"))\nMMPvalue = as.data.frame(corPvalueStudent(as.matrix(geneModuleMembership), nSamples))\nnames(geneModuleMembership) = paste(\"MM\", modNames, sep = \"\")\nnames(MMPvalue) = paste(\"p.MM\", modNames, sep = \"\")\n##计算基因和weight的相关性\ngeneTraitSignificance = as.data.frame(cor(datExpr, weight, use = \"p\"))\nGSPvalue = as.data.frame(corPvalueStudent(as.matrix(geneTraitSignificance), nSamples))\n\nnames(geneTraitSignificance) = paste(\"GS.\", names(weight), sep = \"\")\nnames(GSPvalue) = paste(\"p.GS.\", names(weight), sep = \"\")\nmodule = \"brown\"\ncolumn = match(module, modNames)\nmoduleGenes = moduleColors==module\npar(mfrow = c(1, 1))\nverboseScatterplot(\n  abs(geneModuleMembership[moduleGenes, column]),\n  abs(geneTraitSignificance[moduleGenes, 1]),\n  xlab = paste(\"Module Membership in\", module, \"module\"),\n  ylab = \"Gene significance for body weight\",\n  main = paste(\"Module membership vs. gene significance\\n\"),\n  cex.main = 1.2,\n  cex.lab = 1.2,\n  cex.axis = 1.2,\n  col = module\n)\nhead(names(datExpr))\nhead(names(datExpr)[moduleColors==\"brown\"])\nannot <- \n  read.csv(file = \"WGCNA_test/GeneAnnotation.csv\")\ndim(annot)\nnames(annot)\nprobes = names(datExpr)\nprobes2annot = match(probes, annot$substanceBXH)\n# The following is the number or probes without annotation:\nsum(is.na(probes2annot))\n# Create the starting data frame\ngeneInfo0 = data.frame(substanceBXH = probes,\ngeneSymbol = annot$gene_symbol[probes2annot],\nLocusLinkID = annot$LocusLinkID[probes2annot],\nmoduleColor = moduleColors,\ngeneTraitSignificance,\nGSPvalue)\n# Order modules by their significance for weight\nmodOrder = order(-abs(cor(MEs, weight, use = \"p\")));\n# Add module membership information in the chosen order\nfor (mod in 1:ncol(geneModuleMembership))\n{\noldNames = names(geneInfo0)\ngeneInfo0 = data.frame(geneInfo0, geneModuleMembership[, modOrder[mod]],\nMMPvalue[, modOrder[mod]]);\nnames(geneInfo0) = c(oldNames, paste(\"MM.\", modNames[modOrder[mod]], sep=\"\"),\npaste(\"p.MM.\", modNames[modOrder[mod]], sep=\"\"))\n}\n# Order the genes in the geneInfo variable first by module color, then by geneTraitSignificance\ngeneOrder = order(geneInfo0$moduleColor, -abs(geneInfo0$GS.weight));\ngeneInfo = geneInfo0[geneOrder, ]\nwrite.csv(geneInfo, file = \"WGCNA_test/geneInfo.csv\")"},{"path":"multiomics.html","id":"对module进行分析","chapter":"10 多组学分析","heading":"10.4.4 对module进行分析","text":"在前文中,鉴定出了几个和weight相关的module.一般需要进行GO注释或者KEGG pathway分析.","code":""},{"path":"regularexpression.html","id":"regularexpression","chapter":"11 正则表达式","heading":"11 正则表达式","text":"正则表达式(regular expression)是文本处理中经常用到的方法.正则表达式描述了一种字符串匹配的模式（pattern）.在R中,正则表达式跟其他语言基本一致,要写成文本的格式,也就是需要使用双引号或者单引号括起来.","code":""},{"path":"regularexpression.html","id":"特殊字符","chapter":"11 正则表达式","heading":"11.1 特殊字符","text":"在正则表达式中有一些字符是有特殊含义的,比如点(.),如果只写点,它代表任意字符,这些称之为特殊字符,或者元字符.正则表达式中就有很多这样元字符.总结如下:这里面有很多是和后面的内容重复的,因此这里写的比较简略.如果想要匹配特殊字符,那么需要对其进行转义,这时候就用到了转义符,也就是\\.但是因为转义符本身也是特殊字符,所以它本身还需要一个转义符,就是\\\\.因此比如我们想要匹配点本身,那在pattern中,需要写作\\\\..","code":""},{"path":"regularexpression.html","id":"匹配match","chapter":"11 正则表达式","heading":"11.2 匹配(match)","text":"有一些特殊含义的匹配,在正则表达式有固定表达方式,比如任意一个数字,任意字母等.","code":""},{"path":"regularexpression.html","id":"替换-alternates","chapter":"11 正则表达式","heading":"11.3 替换 (Alternates)","text":"","code":""},{"path":"regularexpression.html","id":"锚点anchors","chapter":"11 正则表达式","heading":"11.4 锚点(anchors)","text":"锚点,又称为定位符,能够将正则表达式固定到行首或行尾。它们还使您能够创建这样的正则表达式，这些正则表达式出现在一个单词内、在一个单词的开头或者一个单词的结尾。","code":""},{"path":"regularexpression.html","id":"以固定要求开头","chapter":"11 正则表达式","heading":"11.4.1 以固定要求开头","text":"以固定要求开头的正则表达式是^,比如我们要查找那些以字母a开头的字符串,就可以写作:在R语言中:","code":"'^a'\ngrep(pattern = \"^a\", x = c(\"abc\", \"bcd\", \"cde\", \"ade\"))\n#> [1] 1 4"},{"path":"regularexpression.html","id":"以固定要求结尾","chapter":"11 正则表达式","heading":"11.4.2 以固定要求结尾","text":"以固定要求结尾的正则表达式是$,比如我们要查找那些以字母a结尾的字符串,就可以写作:在R语言中:","code":"'a$'\ngrep(pattern = \"a$\", x = c(\"abc\", \"bcd\", \"cde\", \"ada\"))\n#> [1] 4"},{"path":"regularexpression.html","id":"数量quantifiers","chapter":"11 正则表达式","heading":"11.5 数量(Quantifiers)","text":"正则表达式中经常需要有一些表达数量的内容,比如重复1次,重复多于一次等等.一般是使用一些特殊字符在某个要重复的内容之后.称之为限定符:重复或者数量还涉及到贪婪和懒惰的问题:","code":""},{"path":"regularexpression.html","id":"整体匹配-groups","chapter":"11 正则表达式","heading":"11.6 整体匹配 (groups)","text":"如果需要将某个对象最为整体进行匹配,一般是使用小括号将其括起来.比如:小括号中就代表一个整体,也即是ab或者d然后后面带着e.","code":"(ab|d)e"},{"path":"regularexpression.html","id":"反义","chapter":"11 正则表达式","heading":"11.7 反义","text":"有时需要查找不属于某个能简单定义的字符类的字符。比如想查找除了数字以外，其它任意字符都行的情况，这时需要用到反义:","code":""},{"path":"tidyverse_purrr.html","id":"tidyverse_purrr","chapter":"12 功能化函数编程purrr","heading":"12 功能化函数编程purrr","text":"purrr是R进行函数化编程(functional programing)的包.","code":""},{"path":"tidyverse_purrr.html","id":"安装-1","chapter":"12 功能化函数编程purrr","heading":"12.1 安装","text":"purrr包在tidyverse包中,所以可以直接通过安装tidyverse包进行安装.当然,也可以单独安装.","code":"\n# The easiest way to get purrr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just purrr:\ninstall.packages(\"purrr\")\n\n# Or the the development version from GitHub:\n# install.packages(\"devtools\")\ndevtools::install_github(\"tidyverse/purrr\")"},{"path":"tidyverse_purrr.html","id":"map函数系列","chapter":"12 功能化函数编程purrr","heading":"12.2 map函数系列","text":"purrr包提供了很多map系列的函数,跟R的base apply家族函数有点像,都是对向量化的对象的每一个元素进行处理.map(.x, .f),其中.x是向量化的对象,比如向量,list等,然后对每一个元素使用.f函数进行处理,得到结果之后会返回一个跟原来.x长度相同的对象.返回对象的格式跟map函数的后缀有关,比如_lgl,_chr()等.在R中,向量包括两类,atomic和list,二者区别在于前者的元素类型必须相同,而后者可以不同,前者的代表为向量和矩阵,而后者为list和数据框.比如map()函数,用法如下:.x是第一个参数,是一个list或者一个atomic vector..f是一个函数,一个公式或者是向量....则是函数的其他参数.我们举个例子:这时候.x是一个向量.函数是rnorm.如果不对函数进行特别说明,则向量的每个元素默认都是函数的第一个参数,然后后面的参数是其他参数.如果在后面对第一参数进行设置,这时候前面的向量则按顺序向后移动.比如:这时候,因为在后面设置了n = 3,因此这时候向量就是rnorm的第二个参数mean了.对于比较复杂的参数,不太推荐这样的写法,更推荐使用匿名函数,然后将参数位置进行固定:当然,也可以是一个公式:这时候参数需要使用.x作为占位符.对于数据框来说,其实也可以看做是一个list,每一列就是一个list中的一个元素.也可以做一些复杂的运算,比如进行scale.从上面的可以看到,使用map函数,最后返回的结果毕竟是一个list.如果想要返回其他的类型呢?这时候需要使用map_加上后缀名的函数,在purrr中一共有以下几种:map_lgl(), map_int(), map_dbl()和map_chr()返回的分别是logical,integer,dbl和character类型的数据.另外,函数还可以是一个列名或者向量某个元素的名字,也就是使用位置参数对其进行提取.比如上面的例子,就是使用函数””,也就是提取对象中名字为””的元素的名字,其实也就是函数[[,如果没有该元素,则使用函数.default的值进行填充.当然,还可以使用位置来进行提取.所以,可以看出来,其实这几个函数都是在map的基础上对返回的数值进行一定的修饰得到不同类型结果而已.map_dfr()和map_dfc()函数.这两个函数其实就是将map()返回的list对象整理为data frame对象.分别按照行和列进行整合.举个例子:walk()函数,称之为游走函数当使用函数的目的是向屏幕提供输出或将文件保存到磁盘——重要的是操作过程而不是返回值，我们应该使用游走函数，而不是映射函数。比如最简单的例子:另外一种是保存文件到本地.这时候就可以使用walk函数.","code":"\nmap(.x, .f, ...)\nlibrary(tidyverse)\n#> ── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n1:3 %>%\n  map(rnorm, mean = 3)\n#> [[1]]\n#> [1] 2.182461\n#> \n#> [[2]]\n#> [1] 3.399001 3.096510\n#> \n#> [[3]]\n#> [1] 3.035313 3.856545 2.756542\n1:3 %>%\n  map(rnorm, n = 3)\n#> [[1]]\n#> [1] 2.280587 1.952189 2.474780\n#> \n#> [[2]]\n#> [1] 4.199993 1.429417 2.415399\n#> \n#> [[3]]\n#> [1] 5.119508 2.234800 2.920658\nmap(.x = 1:3, .f = function(x) {rnorm(n = 3, mean = x)})\n#> [[1]]\n#> [1]  0.6404823 -0.6745768 -0.3239383\n#> \n#> [[2]]\n#> [1] 2.928259 4.679959 3.083319\n#> \n#> [[3]]\n#> [1] 4.818852 1.785982 3.450535\nmap(.x = 1:3, ~ rnorm(n = 3, mean = .x))\n#> [[1]]\n#> [1] 2.092958 1.319695 2.545803\n#> \n#> [[2]]\n#> [1] 1.5566733 3.8584412 0.4771738\n#> \n#> [[3]]\n#> [1] 2.555392 3.502200 2.074673\ndf <- matrix(1:16, nrow = 4) %>% \n  as.data.frame()\ndf\n#>   V1 V2 V3 V4\n#> 1  1  5  9 13\n#> 2  2  6 10 14\n#> 3  3  7 11 15\n#> 4  4  8 12 16\nmap(.x = df, .f = mean)\n#> $V1\n#> [1] 2.5\n#> \n#> $V2\n#> [1] 6.5\n#> \n#> $V3\n#> [1] 10.5\n#> \n#> $V4\n#> [1] 14.5\ndf <- matrix(1:16, nrow = 4) %>% \n  as.data.frame()\ndf\n#>   V1 V2 V3 V4\n#> 1  1  5  9 13\n#> 2  2  6 10 14\n#> 3  3  7 11 15\n#> 4  4  8 12 16\nmap(.x = df, .f = function(x) {(x - mean(x)) / sd(x)})\n#> $V1\n#> [1] -1.1618950 -0.3872983  0.3872983  1.1618950\n#> \n#> $V2\n#> [1] -1.1618950 -0.3872983  0.3872983  1.1618950\n#> \n#> $V3\n#> [1] -1.1618950 -0.3872983  0.3872983  1.1618950\n#> \n#> $V4\n#> [1] -1.1618950 -0.3872983  0.3872983  1.1618950\nset_names(c(\"foo\", \"bar\")) %>% map(paste0, \":suffix\")\n#> $foo\n#> [1] \"foo:suffix\"\n#> \n#> $bar\n#> [1] \"bar:suffix\"\nl1 <- list(list(a = 1L), list(a = NULL, b = 2L), list(b = 3L))\nmap(.x = l1, .f = \"a\", .default = \"???\")\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] \"???\"\n#> \n#> [[3]]\n#> [1] \"???\"\nl1 %>% map_int(\"b\", .default = NA)\n#> [1] NA  2  3\nl1 %>% map_int(2, .default = NA)\n#> [1] NA  2 NA\ndata <- \nmtcars %>%\n  split(.$cyl)\n\ndata <- map(.x = data, .f = ~ lm(mpg ~ wt, data = .x))\n  \ndata <- map(.x = data, .f = summary)\n  \nmap(.x = data, .f = \"r.squared\")\n#> $`4`\n#> [1] 0.5086326\n#> \n#> $`6`\n#> [1] 0.4645102\n#> \n#> $`8`\n#> [1] 0.4229655\nmap_dbl(.x = data, .f = \"r.squared\")\n#>         4         6         8 \n#> 0.5086326 0.4645102 0.4229655\ndf <- matrix(sample(1:20), nrow = 4) %>% \n  as.data.frame()\ndf\n#>   V1 V2 V3 V4 V5\n#> 1  9 13 17  4  7\n#> 2 16  2 12 19 18\n#> 3 14 20 11  6  1\n#> 4 10  8  5  3 15\nmap(.x = df, .f = function(x) {(x - mean(x)) / sd(x)})\n#> $V1\n#> [1] -0.9836449  1.1349749  0.5296549 -0.6809849\n#> \n#> $V2\n#> [1]  0.2948048 -1.1464631  1.2119753 -0.3603170\n#> \n#> $V3\n#> [1]  1.16764809  0.15230192 -0.05076731 -1.26918271\n#> \n#> $V4\n#> [1] -0.5377329  1.4787654 -0.2688664 -0.6721661\n#> \n#> $V5\n#> [1] -0.4210377  1.0040129 -1.1983380  0.6153628\nmap_dfr(.x = df, .f = function(x) {(x - mean(x)) / sd(x)})\n#> # A tibble: 4 × 5\n#>       V1     V2      V3     V4     V5\n#>    <dbl>  <dbl>   <dbl>  <dbl>  <dbl>\n#> 1 -0.984  0.295  1.17   -0.538 -0.421\n#> 2  1.13  -1.15   0.152   1.48   1.00 \n#> 3  0.530  1.21  -0.0508 -0.269 -1.20 \n#> 4 -0.681 -0.360 -1.27   -0.672  0.615\nmap_dfc(.x = df, .f = function(x) {(x - mean(x)) / sd(x)})\n#> # A tibble: 4 × 5\n#>       V1     V2      V3     V4     V5\n#>    <dbl>  <dbl>   <dbl>  <dbl>  <dbl>\n#> 1 -0.984  0.295  1.17   -0.538 -0.421\n#> 2  1.13  -1.15   0.152   1.48   1.00 \n#> 3  0.530  1.21  -0.0508 -0.269 -1.20 \n#> 4 -0.681 -0.360 -1.27   -0.672  0.615\nwalk(.x = 1:10, .f = print)\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n#> [1] 6\n#> [1] 7\n#> [1] 8\n#> [1] 9\n#> [1] 10"},{"path":"tidyverse_purrr.html","id":"map变种函数","chapter":"12 功能化函数编程purrr","heading":"12.3 map变种函数","text":"和map()函数类似,purrr提供了一系列map函数的变种函数.","code":""},{"path":"tidyverse_purrr.html","id":"map2系列函数","chapter":"12 功能化函数编程purrr","heading":"12.3.1 map2系列函数","text":"map2()可以多提供一个输入变量.然后对其同时进行处理.用法如下:.x和.y是两个长度相等的向量.如果其中一个长度为1,那么会对其进行循环..f还是对向量进行处理的函数.举个例子:","code":"\nmap2(.x, .y, .f, ...)\n\nmap2_lgl(.x, .y, .f, ...)\n\nmap2_int(.x, .y, .f, ...)\n\nmap2_dbl(.x, .y, .f, ...)\n\nmap2_chr(.x, .y, .f, ...)\n\nmap2_raw(.x, .y, .f, ...)\n\nmap2_dfr(.x, .y, .f, ..., .id = NULL)\n\nmap2_dfc(.x, .y, .f, ...)\nx <- list(1, 10, 100)\ny <- list(1, 2, 3)\nz <- list(5, 50, 500)\nmap2(.x = x, .y = y, .f = ~ .x + .y)\n#> [[1]]\n#> [1] 2\n#> \n#> [[2]]\n#> [1] 12\n#> \n#> [[3]]\n#> [1] 103\nmap2(.x = x, .y = y, .f = `+`)\n#> [[1]]\n#> [1] 2\n#> \n#> [[2]]\n#> [1] 12\n#> \n#> [[3]]\n#> [1] 103"},{"path":"tidyverse_purrr.html","id":"pmap和pwalk系列函数","chapter":"12 功能化函数编程purrr","heading":"12.3.2 pmap和pwalk系列函数","text":"pmap()和pwalk()比较特殊,他们用法如下:其中.l是指一个列表(list).长度可以为任意值.如果输入的是一个data frame,那么他们是按照行进行处理的.这时候需要和map系列函数区分,以为他们是按照列进行处理的.比如下面的例子:分别将x,y和z的第一个元素,第二个元素和第三个元素相加得到最终的结果.","code":"\npmap(.l, .f, ...)\n\npmap_lgl(.l, .f, ...)\n\npmap_int(.l, .f, ...)\n\npmap_dbl(.l, .f, ...)\n\npmap_chr(.l, .f, ...)\n\npmap_raw(.l, .f, ...)\n\npmap_dfr(.l, .f, ..., .id = NULL)\n\npmap_dfc(.l, .f, ...)\n\npwalk(.l, .f, ...)\npmap(.l = list(x, y, z), .f = sum)\n#> [[1]]\n#> [1] 7\n#> \n#> [[2]]\n#> [1] 62\n#> \n#> [[3]]\n#> [1] 603\npmap(list(x, y, z), function(a, b, c) a / (b + c))\n#> [[1]]\n#> [1] 0.1666667\n#> \n#> [[2]]\n#> [1] 0.1923077\n#> \n#> [[3]]\n#> [1] 0.1988072"},{"path":"biostatistics.html","id":"biostatistics","chapter":"13 Modern Statistics for Modern Biology","heading":"13 Modern Statistics for Modern Biology","text":"","code":""},{"path":"references-1.html","id":"references-1","chapter":"References","heading":"References","text":"","code":""}]
